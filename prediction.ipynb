{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import sys\r\n",
    "import json\r\n",
    "import datetime\r\n",
    "import numpy as np\r\n",
    "import skimage.draw\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "# Root directory of the project\r\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\r\n",
    "# Import Mask RCNN\r\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\r\n",
    "from mrcnn.config import Config\r\n",
    "from mrcnn import model as modellib, utils\r\n",
    "from mrcnn import visualize\r\n",
    "import paper\r\n",
    "import random\r\n",
    "from glob import glob\r\n",
    "\r\n",
    "# Directory to save logs and model checkpoints, if not provided\r\n",
    "# through the command line argument --logs\r\n",
    "\r\n",
    "PRETRAINED_MODEL_PATH = \"C:/Users/darksoul/Mask_RCNN/mask_rcnn_surgery_0030.h5\"\r\n",
    "IMAGE_DIR = \"C:/Users/darksoul/Mask_RCNN/datasets/4points/val\""
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class InferenceConfig(paper.PaperConfig):\r\n",
    "            # Set batch size to 1 since we'll be running inference on\r\n",
    "            # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\r\n",
    "    GPU_COUNT = 1\r\n",
    "    IMAGES_PER_GPU = 1\r\n",
    "config = InferenceConfig()\r\n",
    "config.display()\r\n",
    "\r\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir='C:/Users/darksoul/Mask_RCNN/logs')\r\n",
    "model_path = PRETRAINED_MODEL_PATH\r\n",
    "# or if you want to use the latest trained model, you can use : \r\n",
    "# model_path = model.find_last()[1]\r\n",
    "model.load_weights(model_path, by_name=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction and merge masks "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "file_names = glob(os.path.join(IMAGE_DIR, \"*.jpg\"))\r\n",
    "masks_prediction = np.zeros((1200, 1600, len(file_names)))\r\n",
    "for i in range(len(file_names)):\r\n",
    "    print(i)\r\n",
    "    image = skimage.io.imread(file_names[i])\r\n",
    "    predictions = model.detect([image],  verbose=1)\r\n",
    "    p = predictions[0]\r\n",
    "    masks = p['masks']\r\n",
    "    merged_mask = np.zeros((masks.shape[0], masks.shape[1]))\r\n",
    "    for j in range(masks.shape[2]):\r\n",
    "        merged_mask[masks[:,:,j]==True] = True\r\n",
    "        masks_prediction[:,:,i] = merged_mask\r\n",
    "print(masks_prediction.shape)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Annotations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "PREDICT_DIR = '/home/simon/deeplearning/mask_rcnn/data/surgery/'\r\n",
    "dataset = paper.PaperDataset()\r\n",
    "dataset.load_VIA(PREDICT_DIR, 'predict')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate Accuracy "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accuracy = 0\r\n",
    "precision = 0\r\n",
    "for image_id in range(len(dataset.image_info)):\r\n",
    "    name = dataset.image_info[image_id]['id']\r\n",
    "    file_name = os.path.join(IMAGE_DIR, name)\r\n",
    "    image_id_pred = file_names.index(file_name)\r\n",
    "    merged_mask = masks_prediction[:, :, image_id_pred]\r\n",
    "    \r\n",
    "    annotated_mask = dataset.load_mask(image_id)[0]\r\n",
    "    merged_annotated_mask = np.zeros((1200, 1600))\r\n",
    "    for i in range(annotated_mask.shape[2]):\r\n",
    "        merged_annotated_mask[annotated_mask[:,:,i]==True] = True\r\n",
    "    accuracy  += np.sum(merged_mask==merged_annotated_mask) / (1200 * 1600)\r\n",
    "    all_correct = np.sum(merged_annotated_mask[merged_mask == 1])\r\n",
    "    precision += all_correct / (np.sum(merged_mask))\r\n",
    "print('accuracy:{}'.format(accuracy / len(file_names)))\r\n",
    "print('precision:{}'.format(precision / len(file_names)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trained with 100 images\n",
    "Accuracy: 99.49%\n",
    "Precision:97.02%\n",
    "# Trained with 200 images\n",
    "Accuracy: 99.54%\n",
    "Precision: 96.78%\n",
    "# Trained with 200 images(60 epochs)\n",
    "Accuracy: 99.53%\n",
    "Precision: 97.28%"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize Random IMage"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "file_names = glob(os.path.join(IMAGE_DIR, \"*.jpg\"))\r\n",
    "class_names = ['Paper']\r\n",
    "test_image = skimage.io.imread(file_names[random.randint(0,len(file_names)-1)])\r\n",
    "predictions = model.detect([test_image], verbose=1) # We are replicating the same image to fill up the batch_size\r\n",
    "p = predictions[0]\r\n",
    "visualize.display_instances(test_image, p['rois'], p['masks'], p['class_ids'], \r\n",
    "                            class_names, p['scores'])"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}